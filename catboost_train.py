import pandas as pd
from catboost import CatBoostClassifier
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import accuracy_score, roc_auc_score
import numpy as np
import optuna

# QRT Score è®¡ç®—å‡½æ•°
def qrt_score(y_true, y_pred, sample_weight):
    return np.sum((y_true == y_pred) * sample_weight) / np.sum(sample_weight)

# 1. è¯»å–æ•°æ®
train = pd.read_csv('train_processed.csv')
test = pd.read_csv('test_processed.csv')

# 2. ç‰¹å¾ä¸æ ‡ç­¾
feature_cols = [col for col in train.columns if col.startswith('RET_') and col != 'RET_TARGET']
industry_cols = [col for col in train.columns if col.startswith('CLASS_LEVEL_')]  # ä¿®æ­£ï¼šCLASS_LEVEL_

# ç¡®ä¿ç‰¹å¾åˆ—åœ¨æµ‹è¯•é›†ä¸­ä¹Ÿå­˜åœ¨
common_cols = [col for col in feature_cols if col in test.columns]
common_industry_cols = [col for col in industry_cols if col in test.columns]

if len(common_cols) != len(feature_cols):
    print(f"âš ï¸ è­¦å‘Š: è®­ç»ƒé›†æœ‰ {len(feature_cols)} ä¸ªæ”¶ç›Šç‡ç‰¹å¾ï¼Œæµ‹è¯•é›†åªæœ‰ {len(common_cols)} ä¸ªå…±åŒç‰¹å¾")
    print(f"ç¼ºå¤±æ”¶ç›Šç‡ç‰¹å¾: {set(feature_cols) - set(test.columns)}")

if len(common_industry_cols) != len(industry_cols):
    print(f"âš ï¸ è­¦å‘Š: è®­ç»ƒé›†æœ‰ {len(industry_cols)} ä¸ªè¡Œä¸šç‰¹å¾ï¼Œæµ‹è¯•é›†åªæœ‰ {len(common_industry_cols)} ä¸ªå…±åŒç‰¹å¾")
    print(f"ç¼ºå¤±è¡Œä¸šç‰¹å¾: {set(industry_cols) - set(test.columns)}")

# ä½¿ç”¨å…±åŒçš„ç‰¹å¾
X = train[common_cols + common_industry_cols].copy()  # åŒ…å«è¡Œä¸šåˆ†ç±»ç‰¹å¾
y = (train['target_sign'] > 0).astype(int)  # 1:æ¶¨, 0:ä¸æ¶¨
sample_weights = train['RET_TARGET'].abs().values  # ä½¿ç”¨RET_TARGETç»å¯¹å€¼ä½œä¸ºæƒé‡

# å¤„ç†åˆ†ç±»ç‰¹å¾ï¼šone-hotç‰¹å¾ä¸éœ€è¦ç‰¹æ®Šå¤„ç†
# for col in common_industry_cols:
#     X[col] = X[col].astype(int)
#     if X[col].min() != 0:
#         print(f"âš ï¸ è°ƒæ•´ {col}: æœ€å°å€¼ä» {X[col].min()} è°ƒæ•´ä¸º 0")
#         X[col] = X[col] - X[col].min()

print(f"ç‰¹å¾ç»Ÿè®¡: æ”¶ç›Šç‡ç‰¹å¾ {len(common_cols)} ä¸ª, è¡Œä¸šç‰¹å¾ {len(common_industry_cols)} ä¸ª")
print(f"è¡Œä¸šç‰¹å¾: {common_industry_cols[:5]}...")  # åªæ˜¾ç¤ºå‰5ä¸ª

# 3. ä½¿ç”¨TimeSeriesSplitè¿›è¡Œæ—¶é—´åºåˆ—äº¤å‰éªŒè¯
tscv = TimeSeriesSplit(n_splits=3)

# åˆ’åˆ†éªŒè¯é›†ï¼ˆä½¿ç”¨æ—¶é—´åºåˆ—åˆ†å‰²ï¼‰
train_idx, val_idx = list(tscv.split(X))[-1]  # ä½¿ç”¨æœ€åä¸€ä¸ªåˆ†å‰²ä½œä¸ºéªŒè¯é›†
X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
train_weights = sample_weights[train_idx]
val_weights = sample_weights[val_idx]

print(f"CatBoostè®­ç»ƒæ•°æ®: {X_train.shape[0]} æ ·æœ¬, {X_train.shape[1]} ç‰¹å¾")
print(f"CatBoostéªŒè¯æ•°æ®: {X_val.shape[0]} æ ·æœ¬")
print(f"æƒé‡ç»Ÿè®¡: è®­ç»ƒé›†å¹³å‡æƒé‡={np.mean(train_weights):.4f}, éªŒè¯é›†å¹³å‡æƒé‡={np.mean(val_weights):.4f}")

# 4. è‡ªåŠ¨è°ƒå‚å‡½æ•°
def tune_catboost_params(X_train, X_val, y_train, y_val, train_weights, val_weights, common_industry_cols):
    """ä½¿ç”¨Optunaè‡ªåŠ¨è°ƒå‚CatBoost - ä½¿ç”¨æ ·æœ¬æƒé‡"""
    print("=== å¼€å§‹CatBoostè‡ªåŠ¨è°ƒå‚ (WBCEä¼˜åŒ–) ===")
    
    def objective(trial):
        # å‚è€ƒé‡åŒ–ç«èµ›ä¼˜ç§€åšæ³•ï¼šä¿å®ˆçš„å‚æ•°èŒƒå›´ï¼Œé¿å…è¿‡æ‹Ÿåˆ
        params = {
            'iterations': 1000,
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05, log=True),  # æ›´ä¿å®ˆçš„å­¦ä¹ ç‡
            'depth': trial.suggest_int('depth', 4, 8),  # æ›´ä¿å®ˆçš„æ·±åº¦
            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 3.0, 10.0),  # æ›´å¼ºçš„æ­£åˆ™åŒ–
            'bootstrap_type': 'Bernoulli',
            'subsample': trial.suggest_float('subsample', 0.7, 1.0),  # æ›´ä¿å®ˆçš„é‡‡æ ·
            'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.7, 1.0),
            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 50),  # æ›´ä¸¥æ ¼çš„è¿‡æ‹Ÿåˆæ§åˆ¶
            'random_seed': 42,
            'verbose': 0,
            'thread_count': -1
        }
        
        # å‚è€ƒé‡åŒ–ç«èµ›æ ‡å‡†åšæ³•ï¼šä½¿ç”¨æ—¶é—´åºåˆ—äº¤å‰éªŒè¯é¿å…è¿‡æ‹Ÿåˆ
        tscv = TimeSeriesSplit(n_splits=3)
        
        cv_scores = []
        for train_idx, val_idx in tscv.split(X_train):
            X_cv_train, X_cv_val = X_train.iloc[train_idx], X_train.iloc[val_idx]
            y_cv_train, y_cv_val = y_train.iloc[train_idx], y_train.iloc[val_idx]
            w_cv_train = train_weights[train_idx]  # ä½¿ç”¨å¯¹åº”çš„æƒé‡
            
            # one-hotç‰¹å¾ä¸éœ€è¦ç‰¹æ®Šå¤„ç†
            X_cv_train_processed = X_cv_train.copy()
            X_cv_val_processed = X_cv_val.copy()
            # for col in common_industry_cols:
            #     X_cv_train_processed[col] = X_cv_train_processed[col].astype(int)
            #     X_cv_val_processed[col] = X_cv_val_processed[col].astype(int)
            
                    # ç¡®ä¿å‚æ•°å…¼å®¹æ€§
        safe_params = params.copy()
        # Bernoulli bootstrap type æ”¯æŒ subsampleï¼Œå…¶ä»–ç±»å‹ä¸æ”¯æŒ
        if safe_params.get('bootstrap_type') != 'Bernoulli':
            safe_params.pop('subsample', None)
            
            # æ£€æµ‹GPUå¹¶å¤„ç†å…¼å®¹æ€§
            try:
                test_clf = CatBoostClassifier(task_type='GPU')
                task_type = 'GPU'
            except:
                task_type = 'CPU'
            
            if task_type == 'GPU':
                # GPUæ¨¡å¼ä¸‹ä¸æ”¯æŒcolsample_bylevelï¼Œç§»é™¤è¯¥å‚æ•°
                if 'colsample_bylevel' in safe_params:
                    safe_params.pop('colsample_bylevel')
            
            clf = CatBoostClassifier(task_type=task_type, **safe_params)
            clf.fit(
                X_cv_train_processed, y_cv_train,
                sample_weight=w_cv_train,  # æ·»åŠ æ ·æœ¬æƒé‡
                eval_set=(X_cv_val_processed, y_cv_val),
                early_stopping_rounds=50,
                verbose=0
            )
            
            val_probs = clf.predict_proba(X_cv_val_processed)[:, 1]
            # ä½¿ç”¨QRT Scoreè€Œä¸æ˜¯AUCï¼Œæ›´ç¬¦åˆé‡åŒ–ç«èµ›ç›®æ ‡
            val_pred = (val_probs > 0.5).astype(int) * 2 - 1
            cv_weights = train.loc[X_cv_val.index, 'RET_TARGET'].abs().values
            qrt_score_cv = qrt_score(y_cv_val.values * 2 - 1, val_pred, cv_weights)
            cv_scores.append(qrt_score_cv)
        
        # ä½¿ç”¨äº¤å‰éªŒè¯çš„å¹³å‡QRT Score
        mean_qrt_score = np.mean(cv_scores)
        
        return mean_qrt_score
        

    
    study = optuna.create_study(direction='maximize')
    study.optimize(objective, n_trials=50, show_progress_bar=True)  # å¢åŠ åˆ°50æ¬¡è¯•éªŒä»¥è·å¾—æœ€ä¼˜ç»“æœ
    
    print(f"CatBoostæœ€ä½³ç»¼åˆè¯„åˆ†: {study.best_value:.4f}")
    print(f"CatBoostæœ€ä½³å‚æ•°: {study.best_params}")
    
    return study.best_params

# 4. ä½¿ç”¨æœ€ä¼˜å‚æ•°ï¼ˆè·³è¿‡è°ƒå‚ï¼‰
print("=== ä½¿ç”¨æœ€ä¼˜å‚æ•°è®­ç»ƒ (WBCEä¼˜åŒ–) ===")
print("ğŸ” ä½¿ç”¨å·²æ‰¾åˆ°çš„æœ€ä¼˜å‚æ•°ç›´æ¥è®­ç»ƒ...")

# ä½¿ç”¨ä¼˜åŒ–åçš„æ¿€è¿›å‚æ•° - æœ€åä¸€æï¼
best_params = {
    'iterations': 1500,  # å¢åŠ è¿­ä»£æ¬¡æ•°
    'learning_rate': 0.02,  # é™ä½å­¦ä¹ ç‡ï¼Œæ›´ç¨³å®š
    'depth': 8,  # å¢åŠ æ·±åº¦
    'l2_leaf_reg': 3.0,  # é™ä½æ­£åˆ™åŒ–
    'bootstrap_type': 'Bernoulli',
    'subsample': 0.85,  # å¢åŠ é‡‡æ ·
    'colsample_bylevel': 0.85,  # å¢åŠ ç‰¹å¾é‡‡æ ·
    'min_data_in_leaf': 15,  # é™ä½æœ€å°æ ·æœ¬æ•°
    'random_seed': 42,
    'verbose': 0,
    'thread_count': -1,
    'loss_function': 'Logloss',
    'eval_metric': 'Logloss'
}

print(f"âœ… ä½¿ç”¨æœ€ä¼˜å‚æ•°: {best_params}")

# 5. è®­ç»ƒæ¨¡å‹ - ä½¿ç”¨æ ·æœ¬æƒé‡
print("å¼€å§‹è®­ç»ƒCatBoostæ¨¡å‹ (ä½¿ç”¨WBCE)...")

# æ£€æµ‹GPUå¹¶å¤„ç†å…¼å®¹æ€§
try:
    test_clf = CatBoostClassifier(task_type='GPU')
    task_type = 'GPU'
    print("ä½¿ç”¨GPUè®­ç»ƒ")
except:
    task_type = 'CPU'
    print("ä½¿ç”¨CPUè®­ç»ƒ")

# ç¡®ä¿å‚æ•°å…¼å®¹æ€§
if best_params.get('bootstrap_type') != 'Bernoulli':
    best_params.pop('subsample', None)

if task_type == 'GPU':
    # GPUæ¨¡å¼ä¸‹ä¸æ”¯æŒcolsample_bylevelï¼Œç§»é™¤è¯¥å‚æ•°
    if 'colsample_bylevel' in best_params:
        best_params.pop('colsample_bylevel')

clf = CatBoostClassifier(task_type=task_type, **best_params)
clf.fit(
    X_train, y_train,
    sample_weight=train_weights,  # æ·»åŠ æ ·æœ¬æƒé‡
    eval_set=(X_val, y_val),
    early_stopping_rounds=50,
    verbose=0
)

# 6. éªŒè¯é›†è¯„ä¼°
val_probs = clf.predict_proba(X_val)[:, 1]
y_val_true = y_val.values

# è°ƒä¼˜é˜ˆå€¼
best_score = -1
best_thresh = 0.5
for thresh in np.arange(0.1, 0.9, 0.01):
    val_pred = (val_probs > thresh).astype(int) * 2 - 1
    score = qrt_score(y_val_true * 2 - 1, val_pred, val_weights)
    if score > best_score:
        best_score = score
        best_thresh = thresh

print(f'æœ€ä¼˜é˜ˆå€¼: {best_thresh:.2f}, éªŒè¯é›†QRT Score: {best_score:.4f}')

# 7. æµ‹è¯•é›†é¢„æµ‹
X_test = test[common_cols + common_industry_cols].copy()
# one-hotç‰¹å¾ä¸éœ€è¦ç‰¹æ®Šå¤„ç†
# for col in common_industry_cols:
#     X_test[col] = X_test[col].astype(int)
#     # ç¡®ä¿æµ‹è¯•é›†çš„åˆ†ç±»ç‰¹å¾å€¼ä¸è®­ç»ƒé›†ä¸€è‡´
#     if X_test[col].min() != 0:
#         X_test[col] = X_test[col] - X_test[col].min()

test_probs = clf.predict_proba(X_test)[:, 1]
test_pred = (test_probs > best_thresh).astype(int) * 2 - 1

# 8. ä¿å­˜ç»“æœ
submit = pd.DataFrame({'ID': test['ID'], 'RET_TARGET': test_pred})
submit.to_csv('submit_catboost_wbce.csv', index=False)

# ä¿å­˜æ¦‚ç‡æ–‡ä»¶
val_prob_df = pd.DataFrame({
    'ID': X_val.index,
    'catboost_wbce_prob': val_probs
})
val_prob_df.to_csv('catboost_wbce_val_probs.csv', index=False)

test_prob_df = pd.DataFrame({
    'ID': test['ID'],
    'catboost_wbce_prob': test_probs
})
test_prob_df.to_csv('catboost_wbce_test_probs.csv', index=False)

print("âœ“ CatBoost (WBCE) è®­ç»ƒå®Œæˆ")
print(f"éªŒè¯é›†QRT Score: {best_score:.4f}")
print(f"æäº¤æ–‡ä»¶: submit_catboost_wbce.csv")
print(f"æ¦‚ç‡æ–‡ä»¶: catboost_wbce_val_probs.csv, catboost_wbce_test_probs.csv") 